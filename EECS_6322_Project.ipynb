{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23R5QVO_yGoH"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimAM(nn.Module):\n",
        "    def __init__(self, coeff_lambda=1e-4):\n",
        "        super(SimAM, self).__init__()\n",
        "        self.coeff_lambda = coeff_lambda\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        X: input tensor with shape (batch_size, num_channels, height, width)\n",
        "        \"\"\"\n",
        "        assert X.dim() == 4, \"shape of X must have 4 dimension\"\n",
        "\n",
        "        # spatial size\n",
        "        n = X.shape[2] * X.shape[3] - 1\n",
        "\n",
        "        # square of (t - u)\n",
        "        d = (X - X.mean(dim=[2,3], keepdim=True)).pow(2)\n",
        "        # print(f'd={d}')\n",
        "\n",
        "        # d.sum() / n is channel variance\n",
        "        v = d.sum(dim=[2,3], keepdim=True) / n\n",
        "        # print(f'v={v}')\n",
        "\n",
        "        # E_inv groups all importance of X\n",
        "        E_inv = d / (4 * (v + self.coeff_lambda)) + 0.5\n",
        "        # print(f'E_inv={E_inv}')\n",
        "\n",
        "        # return attended features\n",
        "        return X * F.sigmoid(E_inv)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simam = SimAM()"
      ],
      "metadata": {
        "id": "HFyuZS7JyLXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "for shape in [(1,1,3,3), (1,2,3,3), (2,1,3,3), (32, 3, 32, 32)]:\n",
        "  X = torch.rand(shape)\n",
        "  y = simam(X)\n",
        "\n",
        "  print(X.shape)\n",
        "  print(y.shape)\n",
        "\n",
        "  print('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egpp2SSmyKsR",
        "outputId": "1ecde1da-62c2-4ac9-ba0a-eaa5faab8418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 3, 3])\n",
            "torch.Size([1, 1, 3, 3])\n",
            "\n",
            "\n",
            "torch.Size([1, 2, 3, 3])\n",
            "torch.Size([1, 2, 3, 3])\n",
            "\n",
            "\n",
            "torch.Size([2, 1, 3, 3])\n",
            "torch.Size([2, 1, 3, 3])\n",
            "\n",
            "\n",
            "torch.Size([32, 3, 32, 32])\n",
            "torch.Size([32, 3, 32, 32])\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "model = models.mobilenet_v2(pretrained=True)"
      ],
      "metadata": {
        "id": "QGLn8I0Ay6ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Squeezer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Squeezer, self).__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.squeeze(x, dim=-1)"
      ],
      "metadata": {
        "id": "Kc5ziGIqyc7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_v2_simam = nn.Sequential()\n",
        "\n",
        "for name, module in model.named_children():\n",
        "  if name == 'features':\n",
        "    feature_seq = nn.Sequential()\n",
        "    mobilenet_v2_simam.add_module(name, feature_seq)\n",
        "\n",
        "    for n0, m0 in module.named_children():\n",
        "      if m0._get_name() == \"Conv2dNormActivation\":\n",
        "        block = nn.Sequential()\n",
        "        feature_seq.add_module(n0, block)\n",
        "\n",
        "        for n1, m1 in m0.named_children():\n",
        "          block.add_module(n1, m1)\n",
        "          if (m1._get_name() == \"Conv2d\" or\n",
        "              m1._get_name() == \"BatchNorm2d\"):\n",
        "            block.add_module(f'{n1}_simam', SimAM())\n",
        "\n",
        "      elif m0._get_name() == \"InvertedResidual\":\n",
        "        block_big = nn.Sequential()                                             # BLOCKNAME: InvertedResidual\n",
        "        feature_seq.add_module(n0, block_big)\n",
        "\n",
        "        for n1, m1 in m0.named_children():\n",
        "          block_med = nn.Sequential()                                           # BLOCKNAME: Sequential\n",
        "          block_big.add_module(n1, block_med)\n",
        "\n",
        "          for n2, m2 in m1.named_children():\n",
        "            if m2._get_name() == \"Conv2dNormActivation\":\n",
        "              block_small = nn.Sequential()                                     # BLOCKNAME: Conv2dNormActivation\n",
        "              block_med.add_module(n2, block_small)\n",
        "\n",
        "              for n3, m3 in m2.named_children():\n",
        "                block_small.add_module(n3, m3)\n",
        "                if (m3._get_name() == \"Conv2d\" or\n",
        "                    m3._get_name() == \"BatchNorm2d\"):\n",
        "                  block_small.add_module(f'{n3}_simam', SimAM())\n",
        "            else:\n",
        "              block_med.add_module(n2, m2)\n",
        "              if (m2._get_name() == \"Conv2d\" or\n",
        "                m2._get_name() == \"BatchNorm2d\"):\n",
        "                block_med.add_module(f'{n2}_simam', SimAM())\n",
        "\n",
        "      else:\n",
        "        raise ValueError(\"Sum ting wong\")\n",
        "  else:\n",
        "    # continue\n",
        "    mobilenet_v2_simam.add_module('squeeze0', Squeezer())\n",
        "    mobilenet_v2_simam.add_module('squeeze1', Squeezer())\n",
        "\n",
        "    mobilenet_v2_simam.add_module(name, module)\n",
        "print(mobilenet_v2_simam)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPs-UkQAXmPJ",
        "outputId": "3cd8bebd-8faf-479c-b8ac-4f6ec71f6358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (features): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (0_simam): SimAM()\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1_simam): SimAM()\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1_simam): SimAM()\n",
            "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (8): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (9): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (10): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (11): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (12): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (13): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (14): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (15): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (16): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (17): Sequential(\n",
            "      (conv): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (0_simam): SimAM()\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1_simam): SimAM()\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2_simam): SimAM()\n",
            "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3_simam): SimAM()\n",
            "      )\n",
            "    )\n",
            "    (18): Sequential(\n",
            "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (0_simam): SimAM()\n",
            "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1_simam): SimAM()\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (squeeze0): Squeezer()\n",
            "  (squeeze1): Squeezer()\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.2, inplace=False)\n",
            "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import os\n",
        "\n",
        "if not os.path.isfile('/content/cifar-10-python.tar.gz'):\n",
        "  !wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "if not os.path.exists('/content/cifar-10-batches-py'):\n",
        "  !tar -xf /content/cifar-10-python.tar.gz\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "data = {}\n",
        "\n",
        "for file in glob(\"./cifar-10-batches-py/*\"):\n",
        "  if not file.endswith('.html'):\n",
        "    data[os.path.basename(file)] = unpickle(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfcQ4nvhpHta",
        "outputId": "8d5565c5-091e-4611-abc2-edf771110ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-22 10:26:18--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  55.9MB/s    in 2.9s    \n",
            "\n",
            "2024-03-22 10:26:21 (55.9 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['data_batch_1'][b'data'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "715PZnA-q1JW",
        "outputId": "2d30de20-8b5b-41a3-e3cd-5a299a03e8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3072)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def read_numpy_to_3d(data_1d):\n",
        "  data_3d = np.zeros((data_1d.shape[0], 3, 32, 32))\n",
        "  for i in range(data_1d.shape[0]):\n",
        "    data_3d[i][0] = data_1d[i][0:1024].reshape(32, 32)\n",
        "    data_3d[i][1] = data_1d[i][1024:2048].reshape(32, 32)\n",
        "    data_3d[i][2] = data_1d[i][2048:3072].reshape(32, 32)\n",
        "  return data_3d\n"
      ],
      "metadata": {
        "id": "EbeupCLLrY3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_1_data = read_numpy_to_3d(data['data_batch_1'][b'data'])\n",
        "batch_1_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lp-NgdFtG0j",
        "outputId": "a6997c99-8486-4569-a0c6-0475cb8780af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 59.,  43.,  50., ..., 158., 152., 148.],\n",
              "         [ 16.,   0.,  18., ..., 123., 119., 122.],\n",
              "         [ 25.,  16.,  49., ..., 118., 120., 109.],\n",
              "         ...,\n",
              "         [208., 201., 198., ..., 160.,  56.,  53.],\n",
              "         [180., 173., 186., ..., 184.,  97.,  83.],\n",
              "         [177., 168., 179., ..., 216., 151., 123.]],\n",
              "\n",
              "        [[ 62.,  46.,  48., ..., 132., 125., 124.],\n",
              "         [ 20.,   0.,   8., ...,  88.,  83.,  87.],\n",
              "         [ 24.,   7.,  27., ...,  84.,  84.,  73.],\n",
              "         ...,\n",
              "         [170., 153., 161., ..., 133.,  31.,  34.],\n",
              "         [139., 123., 144., ..., 148.,  62.,  53.],\n",
              "         [144., 129., 142., ..., 184., 118.,  92.]],\n",
              "\n",
              "        [[ 63.,  45.,  43., ..., 108., 102., 103.],\n",
              "         [ 20.,   0.,   0., ...,  55.,  50.,  57.],\n",
              "         [ 21.,   0.,   8., ...,  50.,  50.,  42.],\n",
              "         ...,\n",
              "         [ 96.,  34.,  26., ...,  70.,   7.,  20.],\n",
              "         [ 96.,  42.,  30., ...,  94.,  34.,  34.],\n",
              "         [116.,  94.,  87., ..., 140.,  84.,  72.]]],\n",
              "\n",
              "\n",
              "       [[[154., 126., 105., ...,  91.,  87.,  79.],\n",
              "         [140., 145., 125., ...,  96.,  77.,  71.],\n",
              "         [140., 139., 115., ...,  79.,  68.,  67.],\n",
              "         ...,\n",
              "         [175., 156., 154., ...,  42.,  61.,  93.],\n",
              "         [165., 156., 159., ..., 103., 123., 131.],\n",
              "         [163., 158., 163., ..., 143., 143., 143.]],\n",
              "\n",
              "        [[177., 137., 104., ...,  95.,  90.,  81.],\n",
              "         [160., 153., 125., ...,  99.,  80.,  73.],\n",
              "         [155., 146., 115., ...,  82.,  70.,  69.],\n",
              "         ...,\n",
              "         [167., 154., 160., ...,  34.,  53.,  83.],\n",
              "         [154., 152., 161., ...,  93., 114., 121.],\n",
              "         [148., 148., 156., ..., 133., 134., 133.]],\n",
              "\n",
              "        [[187., 136.,  95., ...,  71.,  71.,  70.],\n",
              "         [169., 154., 118., ...,  78.,  62.,  61.],\n",
              "         [164., 149., 112., ...,  64.,  55.,  55.],\n",
              "         ...,\n",
              "         [166., 160., 170., ...,  36.,  57.,  91.],\n",
              "         [128., 130., 142., ...,  96., 120., 131.],\n",
              "         [120., 122., 133., ..., 139., 142., 144.]]],\n",
              "\n",
              "\n",
              "       [[[255., 253., 253., ..., 253., 253., 253.],\n",
              "         [255., 255., 255., ..., 255., 255., 255.],\n",
              "         [255., 254., 254., ..., 254., 254., 254.],\n",
              "         ...,\n",
              "         [113., 111., 105., ...,  72.,  72.,  72.],\n",
              "         [111., 104.,  99., ...,  68.,  70.,  78.],\n",
              "         [106.,  99.,  95., ...,  78.,  79.,  80.]],\n",
              "\n",
              "        [[255., 253., 253., ..., 253., 253., 253.],\n",
              "         [255., 255., 255., ..., 255., 255., 255.],\n",
              "         [255., 254., 254., ..., 254., 254., 254.],\n",
              "         ...,\n",
              "         [120., 118., 112., ...,  81.,  80.,  80.],\n",
              "         [118., 111., 106., ...,  75.,  76.,  84.],\n",
              "         [113., 106., 102., ...,  85.,  85.,  86.]],\n",
              "\n",
              "        [[255., 253., 253., ..., 253., 253., 253.],\n",
              "         [255., 255., 255., ..., 255., 255., 255.],\n",
              "         [255., 254., 254., ..., 254., 254., 254.],\n",
              "         ...,\n",
              "         [112., 111., 106., ...,  80.,  79.,  79.],\n",
              "         [110., 104.,  98., ...,  73.,  75.,  82.],\n",
              "         [105.,  98.,  94., ...,  83.,  83.,  84.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 71.,  60.,  74., ..., 251., 255., 191.],\n",
              "         [ 89.,  80.,  67., ..., 250., 255., 181.],\n",
              "         [ 74.,  69.,  68., ..., 246., 254., 193.],\n",
              "         ...,\n",
              "         [ 84.,  80.,  80., ...,  41.,  55.,  61.],\n",
              "         [ 67.,  65.,  62., ...,  63.,  68.,  71.],\n",
              "         [ 66.,  66.,  65., ...,  80.,  83.,  84.]],\n",
              "\n",
              "        [[ 77.,  69.,  83., ..., 251., 255., 192.],\n",
              "         [ 96.,  89.,  77., ..., 248., 254., 181.],\n",
              "         [ 80.,  77.,  77., ..., 245., 254., 195.],\n",
              "         ...,\n",
              "         [ 85.,  81.,  80., ...,  43.,  55.,  62.],\n",
              "         [ 66.,  64.,  61., ...,  63.,  66.,  70.],\n",
              "         [ 43.,  44.,  42., ...,  73.,  75.,  77.]],\n",
              "\n",
              "        [[ 44.,  35.,  56., ..., 253., 255., 186.],\n",
              "         [ 62.,  58.,  51., ..., 249., 254., 170.],\n",
              "         [ 46.,  50.,  53., ..., 248., 254., 183.],\n",
              "         ...,\n",
              "         [ 84.,  81.,  80., ...,  48.,  59.,  63.],\n",
              "         [ 67.,  64.,  61., ...,  65.,  67.,  67.],\n",
              "         [ 28.,  28.,  27., ...,  68.,  69.,  68.]]],\n",
              "\n",
              "\n",
              "       [[[250., 254., 211., ..., 188., 255., 255.],\n",
              "         [250., 255., 213., ..., 189., 255., 255.],\n",
              "         [250., 255., 213., ..., 186., 255., 255.],\n",
              "         ...,\n",
              "         [255., 254., 213., ..., 211., 255., 255.],\n",
              "         [255., 252., 217., ..., 214., 255., 255.],\n",
              "         [255., 253., 218., ..., 214., 255., 255.]],\n",
              "\n",
              "        [[255., 253., 224., ..., 195., 255., 254.],\n",
              "         [255., 254., 225., ..., 198., 255., 254.],\n",
              "         [255., 254., 226., ..., 198., 255., 254.],\n",
              "         ...,\n",
              "         [254., 254., 224., ..., 211., 255., 254.],\n",
              "         [254., 253., 225., ..., 213., 255., 254.],\n",
              "         [254., 253., 221., ..., 212., 255., 254.]],\n",
              "\n",
              "        [[255., 254., 220., ..., 193., 255., 255.],\n",
              "         [255., 255., 222., ..., 195., 255., 255.],\n",
              "         [255., 255., 222., ..., 194., 255., 255.],\n",
              "         ...,\n",
              "         [255., 255., 221., ..., 215., 255., 254.],\n",
              "         [255., 253., 222., ..., 216., 255., 254.],\n",
              "         [255., 253., 220., ..., 215., 255., 254.]]],\n",
              "\n",
              "\n",
              "       [[[ 62.,  61.,  60., ...,  64.,  82.,  62.],\n",
              "         [ 62.,  63.,  61., ...,  77., 114.,  64.],\n",
              "         [ 67.,  78., 115., ..., 100., 119.,  63.],\n",
              "         ...,\n",
              "         [161., 159., 159., ..., 152., 157., 156.],\n",
              "         [163., 161., 162., ..., 162., 161., 161.],\n",
              "         [169., 167., 167., ..., 167., 167., 167.]],\n",
              "\n",
              "        [[ 55.,  55.,  55., ...,  58.,  75.,  55.],\n",
              "         [ 56.,  52.,  48., ...,  69., 107.,  57.],\n",
              "         [ 59.,  62.,  93., ...,  92., 111.,  56.],\n",
              "         ...,\n",
              "         [192., 190., 190., ..., 167., 190., 192.],\n",
              "         [195., 192., 193., ..., 191., 193., 193.],\n",
              "         [201., 198., 198., ..., 198., 198., 198.]],\n",
              "\n",
              "        [[  7.,   7.,   6., ...,  10.,  28.,   9.],\n",
              "         [  7.,   8.,   6., ...,  28.,  65.,  12.],\n",
              "         [ 15.,  28.,  66., ...,  58.,  74.,  12.],\n",
              "         ...,\n",
              "         [125., 123., 123., ..., 123., 128., 123.],\n",
              "         [127., 125., 126., ..., 128., 127., 126.],\n",
              "         [132., 130., 131., ..., 130., 130., 131.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "simam(simam(simam(torch.Tensor(batch_1_data))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAFvijXntb8I",
        "outputId": "91f5bee4-0fd0-414e-aec4-03b5ab7c42f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 23.0655,  19.5074,  21.2200,  ...,  38.8042,  37.0070,  35.9787],\n",
              "          [  9.5187,   0.0000,  10.4938,  ...,  31.4538,  30.9181,  31.3168],\n",
              "          [ 13.5731,   9.5187,  20.9917,  ...,  30.7889,  31.0490,  29.6915],\n",
              "          ...,\n",
              "          [ 94.9364,  77.7673,  71.8846,  ...,  39.4849,  22.4895,  21.8755],\n",
              "          [ 49.9837,  45.3290,  55.3085,  ...,  53.3666,  28.3235,  26.6787],\n",
              "          [ 47.8167,  42.7382,  49.2294,  ..., 120.2534,  36.7385,  31.4538]],\n",
              "\n",
              "         [[ 17.7945,  14.8076,  15.2109,  ...,  33.4161,  30.8751,  30.5483],\n",
              "          [  8.1461,   0.0000,   3.6941,  ...,  22.2171,  21.3453,  22.0403],\n",
              "          [  9.3946,   3.2675,  10.2667,  ...,  21.5175,  21.5175,  19.6585],\n",
              "          ...,\n",
              "          [ 64.3999,  45.2705,  52.6999,  ...,  33.8203,  11.3529,  12.1157],\n",
              "          [ 36.5110,  30.2295,  39.1713,  ...,  41.6438,  17.7945,  16.1760],\n",
              "          [ 39.1713,  32.2688,  38.0551,  ...,  92.5291,  28.7433,  22.9396]],\n",
              "\n",
              "         [[ 15.2872,  11.4134,  10.9950,  ...,  30.9284,  27.7663,  28.2555],\n",
              "          [  5.8597,   0.0000,   0.0000,  ...,  13.5221,  12.4608,  13.9539],\n",
              "          [  6.1067,   0.0000,   2.5926,  ...,  12.4608,  12.4608,  10.7855],\n",
              "          ...,\n",
              "          [ 25.0976,   9.0851,   7.2977,  ...,  16.9459,   2.2897,   5.8597],\n",
              "          [ 25.0976,  10.7855,   8.2063,  ...,  24.2972,   9.0851,   9.0851],\n",
              "          [ 36.1769,  24.2972,  21.7788,  ...,  64.2572,  20.8129,  17.4470]]],\n",
              "\n",
              "\n",
              "        [[[ 37.7754,  30.8210,  26.8609,  ...,  24.4326,  23.7437,  22.3502],\n",
              "          [ 33.9457,  35.2138,  30.6166,  ...,  25.2932,  21.9962,  20.9130],\n",
              "          [ 33.9457,  33.7032,  28.6725,  ...,  22.3502,  20.3569,  20.1689],\n",
              "          ...,\n",
              "          [ 45.9054,  38.4032,  37.7754,  ...,  14.8382,  19.0099,  24.7766],\n",
              "          [ 41.5624,  38.4032,  39.3919,  ...,  26.5089,  30.2139,  31.8762],\n",
              "          [ 40.8078,  39.0557,  40.8078,  ...,  34.6949,  34.6949,  34.6949]],\n",
              "\n",
              "         [[ 47.1300,  33.2280,  26.7206,  ...,  25.1754,  24.3258,  22.7862],\n",
              "          [ 39.7910,  37.4960,  30.6206,  ...,  25.8580,  22.6130,  21.3790],\n",
              "          [ 38.1193,  35.4880,  28.6890,  ...,  22.9589,  20.8356,  20.6520],\n",
              "          ...,\n",
              "          [ 42.4558,  37.8046,  39.7910,  ...,  12.8885,  17.4938,  23.1311],\n",
              "          [ 37.8046,  37.1933,  40.1468,  ...,  24.8354,  28.5045,  29.8270],\n",
              "          [ 36.0364,  36.0364,  38.4402,  ...,  32.3151,  32.5387,  32.3151]],\n",
              "\n",
              "         [[ 53.4591,  33.0022,  25.2281,  ...,  21.1027,  21.1027,  20.9216],\n",
              "          [ 43.3529,  37.8177,  29.2729,  ...,  22.3407,  19.4215,  19.2266],\n",
              "          [ 41.2965,  36.3261,  28.1686,  ...,  19.8059,  18.0155,  18.0155],\n",
              "          ...,\n",
              "          [ 42.0898,  39.8147,  43.7950,  ...,  13.5338,  18.4277,  24.5541],\n",
              "          [ 31.2498,  31.6714,  34.4504,  ...,  25.3969,  29.6530,  31.8861],\n",
              "          [ 29.6530,  30.0401,  32.3237,  ...,  33.7100,  34.4504,  34.9639]]],\n",
              "\n",
              "\n",
              "        [[[105.6047, 102.4264, 102.4264,  ..., 102.4264, 102.4264, 102.4264],\n",
              "          [105.6047, 105.6047, 105.6047,  ..., 105.6047, 105.6047, 105.6047],\n",
              "          [105.6047, 103.9990, 103.9990,  ..., 103.9990, 103.9990, 103.9990],\n",
              "          ...,\n",
              "          [ 28.1858,  27.7844,  26.5913,  ...,  20.0261,  20.0261,  20.0261],\n",
              "          [ 27.7844,  26.3937,  25.4090,  ...,  19.1935,  19.6116,  21.2505],\n",
              "          [ 26.7892,  25.4090,  24.6232,  ...,  21.2505,  21.4522,  21.6533]],\n",
              "\n",
              "         [[105.6243, 102.4067, 102.4067,  ..., 102.4067, 102.4067, 102.4067],\n",
              "          [105.6243, 105.6243, 105.6243,  ..., 105.6243, 105.6243, 105.6243],\n",
              "          [105.6243, 103.9985, 103.9985,  ..., 103.9985, 103.9985, 103.9985],\n",
              "          ...,\n",
              "          [ 29.6945,  29.2889,  28.0889,  ...,  22.0178,  21.8185,  21.8185],\n",
              "          [ 29.2889,  27.8909,  26.9074,  ...,  20.8127,  21.0153,  22.6123],\n",
              "          [ 28.2874,  26.9074,  26.1262,  ...,  22.8095,  22.8095,  23.0063]],\n",
              "\n",
              "         [[108.3629, 105.0229, 105.0229,  ..., 105.0229, 105.0229, 105.0229],\n",
              "          [108.3629, 108.3629, 108.3629,  ..., 108.3629, 108.3629, 108.3629],\n",
              "          [108.3629, 106.6758, 106.6758,  ..., 106.6758, 106.6758, 106.6758],\n",
              "          ...,\n",
              "          [ 27.9725,  27.7722,  26.7780,  ...,  21.6569,  21.4565,  21.4565],\n",
              "          [ 27.5724,  26.3831,  25.2045,  ...,  20.2410,  20.6489,  22.0560],\n",
              "          [ 26.5804,  25.2045,  24.4208,  ...,  22.2548,  22.2548,  22.4532]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[ 18.5738,  16.3045,  19.1830,  ..., 160.9222, 170.9431,  59.8780],\n",
              "          [ 22.2275,  20.3975,  17.7565,  ..., 158.4249, 170.9431,  52.6599],\n",
              "          [ 19.1830,  18.1660,  17.9615,  ..., 148.5263, 168.4369,  61.5367],\n",
              "          ...,\n",
              "          [ 21.2080,  20.3975,  20.3975,  ...,  12.1002,  15.2425,  16.5141],\n",
              "          [ 17.7565,  17.3450,  16.7229,  ...,  16.9309,  17.9615,  18.5738],\n",
              "          [ 17.5510,  17.5510,  17.3450,  ...,  20.3975,  21.0051,  21.2080]],\n",
              "\n",
              "         [[ 19.6039,  17.9624,  20.8356,  ..., 163.9310, 173.8862,  62.0192],\n",
              "          [ 23.5573,  22.0787,  19.6039,  ..., 156.4944, 171.3986,  53.6398],\n",
              "          [ 20.2189,  19.6039,  19.6039,  ..., 149.1390, 171.3986,  64.7056],\n",
              "          ...,\n",
              "          [ 21.2482,  20.4242,  20.2189,  ...,  12.3567,  15.0253,  16.5099],\n",
              "          [ 17.3428,  16.9274,  16.3001,  ...,  16.7190,  17.3428,  18.1682],\n",
              "          [ 12.3567,  12.5868,  12.1250,  ...,  18.7843,  19.1942,  19.6039]],\n",
              "\n",
              "         [[ 11.4562,   9.3609,  14.1587,  ..., 161.0590, 165.5159,  60.1947],\n",
              "          [ 15.4900,  14.6032,  13.0416,  ..., 152.2467, 163.2841,  49.5826],\n",
              "          [ 11.9124,  12.8169,  13.4896,  ..., 150.0716, 163.2841,  57.9535],\n",
              "          ...,\n",
              "          [ 20.4143,  19.7297,  19.5029,  ...,  12.3658,  14.8251,  15.7114],\n",
              "          [ 16.5973,  15.9328,  15.2685,  ...,  16.1543,  16.5973,  16.5973],\n",
              "          [  7.6687,   7.6687,   7.4214,  ...,  16.8190,  17.0408,  16.8190]]],\n",
              "\n",
              "\n",
              "        [[[126.0407, 134.2232,  70.4809,  ...,  53.6023, 136.3330, 136.3330],\n",
              "          [126.0407, 136.3330,  72.3692,  ...,  54.1864, 136.3330, 136.3330],\n",
              "          [126.0407, 136.3330,  72.3692,  ...,  52.4665, 136.3330, 136.3330],\n",
              "          ...,\n",
              "          [136.3330, 134.2232,  72.3692,  ...,  70.4809, 136.3330, 136.3330],\n",
              "          [136.3330, 130.0791,  76.4006,  ...,  73.3445, 136.3330, 136.3330],\n",
              "          [136.3330, 132.1383,  77.4644,  ...,  73.3445, 136.3330, 136.3330]],\n",
              "\n",
              "         [[139.6640, 134.8453,  81.4613,  ...,  55.0832, 139.6640, 137.2407],\n",
              "          [139.6640, 137.2407,  82.7691,  ...,  57.0173, 139.6640, 137.2407],\n",
              "          [139.6640, 137.2407,  84.1112,  ...,  57.0173, 139.6640, 137.2407],\n",
              "          ...,\n",
              "          [137.2407, 137.2407,  81.4613,  ...,  67.2278, 139.6640, 137.2407],\n",
              "          [137.2407, 134.8453,  82.7691,  ...,  69.1168, 139.6640, 137.2407],\n",
              "          [137.2407, 134.8453,  77.7358,  ...,  68.1601, 139.6640, 137.2407]],\n",
              "\n",
              "         [[134.5262, 132.2308,  75.3268,  ...,  53.6512, 134.5262, 134.5262],\n",
              "          [134.5262, 134.5262,  77.5772,  ...,  54.8313, 134.5262, 134.5262],\n",
              "          [134.5262, 134.5262,  77.5772,  ...,  54.2349, 134.5262, 134.5262],\n",
              "          ...,\n",
              "          [134.5262, 134.5262,  76.4378,  ...,  70.1723, 134.5262, 132.2308],\n",
              "          [134.5262, 129.9656,  77.5772,  ...,  71.1521, 134.5262, 132.2308],\n",
              "          [134.5262, 129.9656,  75.3268,  ...,  70.1723, 134.5262, 132.2308]]],\n",
              "\n",
              "\n",
              "        [[[ 22.8520,  22.6804,  22.5057,  ...,  23.1863,  25.7924,  22.8520],\n",
              "          [ 22.8520,  23.0206,  22.6804,  ...,  25.1257,  29.8181,  23.1863],\n",
              "          [ 23.6672,  25.2617,  29.9535,  ...,  28.0339,  30.5109,  23.0206],\n",
              "          ...,\n",
              "          [ 40.1164,  39.3651,  39.3651,  ...,  37.0892,  38.6624,  38.3278],\n",
              "          [ 40.9215,  40.1164,  40.5119,  ...,  40.5119,  40.1164,  40.1164],\n",
              "          [ 43.7202,  42.7164,  42.7164,  ...,  42.7164,  42.7164,  42.7164]],\n",
              "\n",
              "         [[ 23.7340,  23.7340,  23.7340,  ...,  24.2494,  26.6198,  23.7340],\n",
              "          [ 23.9100,  23.1789,  22.3681,  ...,  25.8694,  29.9739,  24.0817],\n",
              "          [ 24.4131,  24.8827,  28.5613,  ...,  28.4603,  30.3932,  23.9100],\n",
              "          ...,\n",
              "          [ 70.1580,  66.2677,  66.2677,  ...,  42.6588,  66.2677,  70.1580],\n",
              "          [ 76.8127,  70.1580,  72.2647,  ...,  68.1600,  72.2647,  72.2647],\n",
              "          [ 93.0955,  84.4776,  84.4776,  ...,  84.4776,  84.4776,  84.4776]],\n",
              "\n",
              "         [[  2.9284,   2.9284,   2.5380,  ...,   4.0489,   9.5033,   3.6836],\n",
              "          [  2.9284,   3.3102,   2.5380,  ...,   9.5033,  17.1698,   4.7563],\n",
              "          [  5.7630,   9.5033,  17.3533,  ...,  15.8769,  18.8284,   4.7563],\n",
              "          ...,\n",
              "          [ 31.9862,  31.1818,  31.1818,  ...,  31.1818,  33.2797,  31.1818],\n",
              "          [ 32.8362,  31.9862,  32.4052,  ...,  33.2797,  32.8362,  32.4052],\n",
              "          [ 35.1908,  34.2065,  34.6911,  ...,  34.2065,  34.2065,  34.6911]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.Tensor(batch_1_data[0:3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eY1F2mxv194",
        "outputId": "47de0591-0502-46d0-c435-d7047b7c1e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-5.6307,  1.8367,  1.0201,  ...,  0.1076,  6.6831, -3.8734],\n",
              "        [-0.7303, -0.8216,  0.5331,  ...,  0.7346, -3.8684,  8.8462],\n",
              "        [ 2.5241, -2.8335, -3.4567,  ..., -0.4353, -0.0102,  1.9500]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_1_data = batch_1_data/256"
      ],
      "metadata": {
        "id": "SNubggXoxwRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_v2_simam[0][:-5](torch.Tensor(batch_1_data[0:3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkStEaqTuIgb",
        "outputId": "14257b51-1320-4623-af90-7959e5163cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.1933,  0.1395],\n",
              "          [-0.0240, -0.2220]],\n",
              "\n",
              "         [[-0.0145,  0.1435],\n",
              "          [-0.4159,  0.0389]],\n",
              "\n",
              "         [[-0.3909,  0.1966],\n",
              "          [-0.0850,  0.0158]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.3911, -0.0119],\n",
              "          [ 0.0265, -0.0870]],\n",
              "\n",
              "         [[-0.0356, -0.0198],\n",
              "          [-0.1628, -0.0181]],\n",
              "\n",
              "         [[ 0.0483, -0.0288],\n",
              "          [-0.0852, -0.2260]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0819, -0.3597],\n",
              "          [-0.0663, -0.3055]],\n",
              "\n",
              "         [[-0.0030,  0.2442],\n",
              "          [-0.2517,  0.0160]],\n",
              "\n",
              "         [[-0.0503,  0.1545],\n",
              "          [ 0.0985, -0.0068]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.0401, -0.1218],\n",
              "          [ 0.2835, -0.0725]],\n",
              "\n",
              "         [[-0.2323,  0.5693],\n",
              "          [-0.3577, -0.0713]],\n",
              "\n",
              "         [[-0.0723, -0.2503],\n",
              "          [-0.1873,  0.0859]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2843,  0.1122],\n",
              "          [ 0.0503,  0.1194]],\n",
              "\n",
              "         [[ 0.6483, -0.1161],\n",
              "          [ 0.1379, -0.4479]],\n",
              "\n",
              "         [[-0.0209,  0.0130],\n",
              "          [ 0.2123, -0.1407]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.0434,  0.1282],\n",
              "          [ 0.5715, -0.2011]],\n",
              "\n",
              "         [[ 0.6123, -0.1583],\n",
              "          [ 0.0469, -0.0567]],\n",
              "\n",
              "         [[-0.1905,  0.5235],\n",
              "          [ 0.2690,  0.1088]]]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.Sequential(mobilenet_v2_simam[0][:-5],\n",
        "              mobilenet_v2_simam[0][-5][0][:-5],\n",
        "              mobilenet_v2_simam[0][-5][0][-5][:-4],\n",
        "              mobilenet_v2_simam[0][-5][0][-5][-4])(torch.Tensor(torch.rand(3,3,32,32)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lDT5FNFs3tu",
        "outputId": "4023ccf7-1f11-421a-8efb-227991956746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.0257]],\n",
              "\n",
              "         [[-0.0045]],\n",
              "\n",
              "         [[ 0.0171]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.0314]],\n",
              "\n",
              "         [[ 0.0006]],\n",
              "\n",
              "         [[-0.0120]]],\n",
              "\n",
              "\n",
              "        [[[-0.0276]],\n",
              "\n",
              "         [[-0.0285]],\n",
              "\n",
              "         [[ 0.0091]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.0593]],\n",
              "\n",
              "         [[ 0.0162]],\n",
              "\n",
              "         [[-0.0264]]],\n",
              "\n",
              "\n",
              "        [[[-0.0200]],\n",
              "\n",
              "         [[-0.0220]],\n",
              "\n",
              "         [[ 0.0000]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.0304]],\n",
              "\n",
              "         [[ 0.0025]],\n",
              "\n",
              "         [[-0.0186]]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_v2_simam[0][-5][0][-5][-4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44KRmi62uZvm",
        "outputId": "e32af417-f17b-451e-e400-7da753b21bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimAM()"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_v2_simam[0][-5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsKAoPlftuh3",
        "outputId": "5e3d2892-fd5b-495a-8355-5b2163fe9dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (conv): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (0_simam): SimAM()\n",
              "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1_simam): SimAM()\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "      (0_simam): SimAM()\n",
              "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1_simam): SimAM()\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (2_simam): SimAM()\n",
              "    (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3_simam): SimAM()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}